{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import (CommaSeparatedListOutputParser,DatetimeOutputParser)\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate\n",
    "from langchain_openai import (OpenAI,ChatOpenAI)\n",
    "import os\n",
    "\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "# 创建一个输出解析器，用于处理带逗号分隔的列表输出\n",
    "output_parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "# 获取格式化指令，该指令告诉模型如何格式化其输出\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "\n",
    "\n",
    "MODEL_NAME = \"gpt-3.5-turbo\"\n",
    "\n",
    "llm = OpenAI(model='davinci-002',openai_proxy=os.getenv(\"OPENAI_BASE_URL\"),max_tokens=1000)\n",
    "\n",
    "chat_model  = ChatOpenAI(model=MODEL_NAME,openai_proxy=os.getenv(\"OPENAI_BASE_URL\"),max_tokens=1000)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ChatPromptTemplate.from_template() missing 1 required positional argument: 'template'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 创建一个提示模板，它会基于给定的模板和变量来生成提示\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m template \u001b[38;5;241m=\u001b[39m \u001b[43mChatPromptTemplate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_template\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a helpful AI bot\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhuman\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mList five \u001b[39;49m\u001b[38;5;132;43;01m{subject}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;132;43;01m{format_instructions}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# 使用提示模板和给定的主题来格式化输入\u001b[39;00m\n\u001b[0;32m      8\u001b[0m messages \u001b[38;5;241m=\u001b[39m template\u001b[38;5;241m.\u001b[39mformat_messages(subject\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mice cream flavors\u001b[39m\u001b[38;5;124m\"\u001b[39m,format_instructions\u001b[38;5;241m=\u001b[39mformat_instructions)\n",
      "\u001b[1;31mTypeError\u001b[0m: ChatPromptTemplate.from_template() missing 1 required positional argument: 'template'"
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建一个提示模板，它会基于给定的模板和变量来生成提示\n",
    "template = ChatPromptTemplate.from_messages(messages=[\n",
    "    (\"system\", \"You are a helpful AI bot\"),\n",
    "    (\"human\", \"List five {subject}.\\n{format_instructions}\"),\n",
    "])\n",
    "\n",
    "# 使用提示模板和给定的主题来格式化输入\n",
    "messages = template.format_messages(subject=\"ice cream flavors\",format_instructions=format_instructions)\n",
    "\n",
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful AI bot'),\n",
       " HumanMessage(content='List five ice cream flavors.\\nYour response should be a list of comma separated values, eg: `foo, bar, baz`')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_model.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vanilla',\n",
       " 'Chocolate',\n",
       " 'Strawberry',\n",
       " 'Mint Chocolate Chip',\n",
       " 'Cookies and Cream']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_parser.parse(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = DatetimeOutputParser()\n",
    "prompt = \"\"\"Answer the users question:\n",
    "\n",
    "{question}\n",
    "\n",
    "{format_instructions}\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个提示模板，它会基于给定的模板和变量来生成提示\n",
    "template = ChatPromptTemplate.from_messages(messages=[\n",
    "    (\"system\", \"You are a helpful AI bot\"),\n",
    "    (\"human\", prompt),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['format_instructions', 'question'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a helpful AI bot')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'question'], template='Answer the users question:\\n\\n{question}\\n\\n{format_instructions}'))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = template.format_messages(question=\"What is your name?\",format_instructions=output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI bot'), HumanMessage(content=\"Answer the users question:\\n\\nWhat is your name?\\n\\nWrite a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 1563-12-14T22:50:21.767891Z, 1436-06-02T21:03:14.716728Z, 1793-04-22T21:37:20.840141Z\\n\\nReturn ONLY this string, no other words!\")]\n"
     ]
    }
   ],
   "source": [
    "print(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2023, 8, 15, 18, 30, 45, 123456)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat_model.invoke(messages)\n",
    "\n",
    "output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['format_instructions', 'question'] messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['format_instructions', 'question'], template='Answer the users question:\\n\\n{question}\\n\\n{format_instructions}'))]\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Answer the users question:\n",
    "\n",
    "{question}\n",
    "\n",
    "{format_instructions}\"\"\"\n",
    "\n",
    "template = ChatPromptTemplate.from_template(\n",
    "    prompt\n",
    ")\n",
    "\n",
    "print(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content=\"Answer the users question:\\n\\naround when was bitcoin founded?\\n\\nWrite a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\\n\\nExamples: 1940-05-10T18:19:18.538399Z, 1830-04-12T18:54:32.408249Z, 0861-08-10T15:21:41.415657Z\\n\\nReturn ONLY this string, no other words!\")]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template.format_messages(question='around when was bitcoin founded?',format_instructions=output_parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2022, 11, 15, 18, 30, 45, 123456)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat_model.invoke(messages)\n",
    "\n",
    "output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: 您是一位专业的鲜花店文案撰写员。\n",
      "对于售价为 50 元的 玫瑰 ，您能提供一个吸引人的简短描述吗？\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"description\": string  // 鲜花的描述文案\n",
      "\t\"reason\": string  // 问什么要这样写这个文案\n",
      "}\n",
      "```\n",
      "content='```json\\n{\\n\\t\"description\": \"这束粉色玫瑰散发着浪漫的芬芳，是表达爱意和感激的完美选择。\",\\n\\t\"reason\": \"这段描述能够吸引顾客，让他们感受到购买这束玫瑰的浪漫和感动，增加购买欲望。\"\\n}\\n```' response_metadata={'finish_reason': 'stop', 'logprobs': None}\n",
      "Human: 您是一位专业的鲜花店文案撰写员。\n",
      "对于售价为 30 元的 百合 ，您能提供一个吸引人的简短描述吗？\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"description\": string  // 鲜花的描述文案\n",
      "\t\"reason\": string  // 问什么要这样写这个文案\n",
      "}\n",
      "```\n",
      "content='```json\\n{\\n\\t\"description\": \"清新优雅的百合，散发着淡淡芬芳，送给心爱的人，传递浪漫与美好。\",\\n\\t\"reason\": \"这样的描述可以让顾客感受到百合的优雅和浪漫之美，吸引他们购买。\"\\n}\\n```' response_metadata={'finish_reason': 'stop', 'logprobs': None}\n",
      "Human: 您是一位专业的鲜花店文案撰写员。\n",
      "对于售价为 20 元的 康乃馨 ，您能提供一个吸引人的简短描述吗？\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"description\": string  // 鲜花的描述文案\n",
      "\t\"reason\": string  // 问什么要这样写这个文案\n",
      "}\n",
      "```\n",
      "content='```json\\n{\\n\\t\"description\": \"清新淡雅的康乃馨，花瓣细腻，花香扑鼻，送给你最爱的人，表达心中的感恩与爱意。\",\\n\\t\"reason\": \"这样的描述可以突出康乃馨的特点，吸引顾客的注意并传达情感，增加购买欲望。\"\\n}\\n```' response_metadata={'finish_reason': 'stop', 'logprobs': None}\n",
      "[{'flower': '玫瑰', 'price': '50', 'description': '这束粉色玫瑰散发着浪漫的芬芳，是表达爱意和感激的完美选择。', 'reason': '这段描述能够吸引顾客，让他们感受到购买这束玫瑰的浪漫和感动，增加购买欲望。'}, {'flower': '百合', 'price': '30', 'description': '清新优雅的百合，散发着淡淡芬芳，送给心爱的人，传递浪漫与美好。', 'reason': '这样的描述可以让顾客感受到百合的优雅和浪漫之美，吸引他们购买。'}, {'flower': '康乃馨', 'price': '20', 'description': '清新淡雅的康乃馨，花瓣细腻，花香扑鼻，送给你最爱的人，表达心中的感恩与爱意。', 'reason': '这样的描述可以突出康乃馨的特点，吸引顾客的注意并传达情感，增加购买欲望。'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 创建提示模板\n",
    "prompt_template = \"\"\"您是一位专业的鲜花店文案撰写员。\n",
    "对于售价为 {price} 元的 {flower_name} ，您能提供一个吸引人的简短描述吗？\n",
    "{format_instructions}\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# 导入结构化输出解析器和ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema\n",
    "# 定义我们想要接收的响应模式\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"description\", description=\"鲜花的描述文案\"),\n",
    "    ResponseSchema(name=\"reason\", description=\"问什么要这样写这个文案\")\n",
    "]\n",
    "# 创建输出解析器\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n",
    "\n",
    "# 获取格式指示\n",
    "format_instructions = output_parser.get_format_instructions()\n",
    "# 根据模板创建提示，同时在提示中加入输出解析器的说明\n",
    "prompt = ChatPromptTemplate.from_template(prompt_template, \n",
    "                partial_variables={\"format_instructions\": format_instructions}) \n",
    "\n",
    "# 数据准备\n",
    "flowers = [\"玫瑰\", \"百合\", \"康乃馨\"]\n",
    "prices = [\"50\", \"30\", \"20\"]\n",
    "\n",
    "# 创建一个空的DataFrame用于存储结果\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(columns=[\"flower\", \"price\", \"description\", \"reason\"]) # 先声明列名\n",
    "\n",
    "for flower, price in zip(flowers, prices):\n",
    "    # 根据提示准备模型的输入\n",
    "    input = prompt.format(flower_name=flower, price=price)\n",
    "    \n",
    "    print(input)\n",
    "\n",
    "\n",
    "    # 获取模型的输出\n",
    "    output = chat_model.invoke(input)\n",
    "    \n",
    "    print(output)\n",
    "    \n",
    "    # 解析模型的输出（这是一个字典结构）\n",
    "    parsed_output = output_parser.parse(output.content)\n",
    "\n",
    "    # 在解析后的输出中添加“flower”和“price”\n",
    "    parsed_output['flower'] = flower\n",
    "    parsed_output['price'] = price\n",
    "\n",
    "    # 将解析后的输出添加到DataFrame中\n",
    "    df.loc[len(df)] = parsed_output  \n",
    "\n",
    "# 打印字典\n",
    "print(df.to_dict(orient='records'))\n",
    "\n",
    "# 保存DataFrame到CSV文件\n",
    "df.to_csv(\"flowers_with_descriptions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
