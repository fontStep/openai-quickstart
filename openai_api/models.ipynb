{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "client.models.list()获取模型 ID 列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = client.models.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'),\n",
       " Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'),\n",
       " Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'),\n",
       " Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'),\n",
       " Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'),\n",
       " Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'),\n",
       " Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-0301', created=1677649963, object='model', owned_by='openai'),\n",
       " Model(id='gpt-3.5-turbo-0613', created=1686587434, object='model', owned_by='openai'),\n",
       " Model(id='gpt-4-vision-preview', created=1698894917, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'),\n",
       " Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'),\n",
       " Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'),\n",
       " Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'),\n",
       " Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'),\n",
       " Model(id='davinci-002', created=1692634301, object='model', owned_by='system'),\n",
       " Model(id='babbage-002', created=1692634615, object='model', owned_by='system'),\n",
       " Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'),\n",
       " Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'),\n",
       " Model(id='gpt-3.5-turbo-16k-0613', created=1685474247, object='model', owned_by='openai'),\n",
       " Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id_list =[model.id for  model in models.data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gpt-3.5-turbo-1106',\n",
       " 'dall-e-3',\n",
       " 'gpt-4-0613',\n",
       " 'dall-e-2',\n",
       " 'gpt-3.5-turbo-0125',\n",
       " 'gpt-4',\n",
       " 'whisper-1',\n",
       " 'tts-1-hd-1106',\n",
       " 'tts-1-hd',\n",
       " 'text-embedding-3-large',\n",
       " 'gpt-3.5-turbo-0301',\n",
       " 'gpt-3.5-turbo-0613',\n",
       " 'gpt-4-vision-preview',\n",
       " 'gpt-3.5-turbo-16k',\n",
       " 'gpt-3.5-turbo',\n",
       " 'gpt-4-1106-preview',\n",
       " 'gpt-3.5-turbo-instruct',\n",
       " 'gpt-3.5-turbo-instruct-0914',\n",
       " 'gpt-4-0125-preview',\n",
       " 'gpt-4-turbo-preview',\n",
       " 'tts-1',\n",
       " 'davinci-002',\n",
       " 'babbage-002',\n",
       " 'tts-1-1106',\n",
       " 'text-embedding-ada-002',\n",
       " 'gpt-3.5-turbo-16k-0613',\n",
       " 'text-embedding-3-small']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_id_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve Model 获取指定模型实例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将模型 ID 传入 retrieve 接口\n",
    "gpt_3 = client.models.retrieve(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai')\n"
     ]
    }
   ],
   "source": [
    "print(gpt_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本内容补全初探（Completions API）[Legacy]\n",
    "使用 Completions API 实现各类文本生成任务\n",
    "\n",
    "主要请求参数说明：\n",
    "\n",
    "model （string，必填）\n",
    "\n",
    "要使用的模型的 ID。可以参考 模型端点兼容性表。\n",
    "\n",
    "prompt （string or array，必填，Defaults to ）\n",
    "\n",
    "生成补全的提示，编码为字符串、字符串数组、token数组或token数组数组。\n",
    "\n",
    "注意，这是模型在训练过程中看到的文档分隔符，所以如果没有指定提示符，模型将像从新文档的开头一样生成。\n",
    "\n",
    "stream （boolean，选填，默认 false）\n",
    "\n",
    "当它设置为 true 时，API 会以 SSE（ Server Side Event ）方式返回内容，即会不断地输出内容直到完成响应，流通过 data: [DONE] 消息终止。\n",
    "\n",
    "max_tokens （integer，选填，默认是 16）\n",
    "\n",
    "补全时要生成的最大 token 数。\n",
    "\n",
    "提示 max_tokens 的 token 计数不能超过模型的上下文长度。大多数模型的上下文长度为 2048 个token（最新模型除外，它支持 4096）\n",
    "\n",
    "temperature （number，选填，默认是1）\n",
    "\n",
    "使用哪个采样温度，在 0和2之间。\n",
    "\n",
    "较高的值，如0.8会使输出更随机，而较低的值，如0.2会使其更加集中和确定性。\n",
    "\n",
    "通常建议修改这个（temperature ）或 top_p 但两者不能同时存在，二选一。\n",
    "\n",
    "n （integer，选填，默认为 1）\n",
    "\n",
    "每个 prompt 生成的补全次数。\n",
    "\n",
    "注意：由于此参数会生成许多补全，因此它会快速消耗token配额。小心使用，并确保对 max_tokens 和 stop 进行合理的设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=\"Say this is a test\",\n",
    "  max_tokens=7,\n",
    "  temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nThis is a test.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.choices[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=\"讲10个给程序员听得笑话\",\n",
    "  max_tokens=1000,\n",
    "  temperature=0.5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "1. 为什么程序员喜欢用8进制？因为7 8 9。\n",
      "2. 为什么程序员总是喜欢喝茶？因为他们喜欢在代码中加入一点Java。\n",
      "3. 为什么程序员总是懒惰？因为他们总是在寻找最简洁的解决方案。\n",
      "4. 为什么程序员总是喜欢熬夜？因为他们觉得夜晚的bug比白天少。\n",
      "5. 为什么程序员总是喜欢穿黑色衣服？因为黑色是最简洁的颜色。\n",
      "6. 为什么程序员总是喜欢用英文命名变量？因为他们觉得中文命名太麻烦。\n",
      "7. 为什么程序员总是喜欢用Linux系统？因为他们觉得Windows系统有太多的bug。\n",
      "8. 为什么程序员总是喜欢吃方便面？因为他们觉得代码也是方便面，只需要加热就可以了。\n",
      "9. 为什么程序员总是喜欢用Git？因为他们觉得Git是最酷的版本控制系统。\n",
      "10. 为什么程序员总是喜欢用注释？因为他们觉得注释是唯一能够解释代码的东西。\n"
     ]
    }
   ],
   "source": [
    "print(data.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=\"生成可执行的快速排序 Python 代码\",\n",
    "  max_tokens=1000,\n",
    "  temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "def quick_sort(arr):\n",
      "    if len(arr) <= 1:\n",
      "        return arr\n",
      "    pivot = arr[0]\n",
      "    left = [x for x in arr[1:] if x <= pivot]\n",
      "    right = [x for x in arr[1:] if x > pivot]\n",
      "    return quick_sort(left) + [pivot] + quick_sort(right)\n",
      "[1, 1, 2, 3, 6, 8, 10, 12]\n"
     ]
    }
   ],
   "source": [
    "text = data.choices[0].text\n",
    "print(text)\n",
    "exec(text)\n",
    "# 现在你可以调用这个函数了\n",
    "print(quick_sort([12,3,6,8,10,1,2,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "聊天机器人初探（Chat Completions API）\n",
    "使用 Chat Completions API 实现对话任务\n",
    "\n",
    "聊天补全(Chat Completions API)以消息列表作为输入，并返回模型生成的消息作为输出。尽管聊天格式旨在使多轮对话变得简单，但它同样适用于没有任何对话的单轮任务。\n",
    "\n",
    "主要请求参数说明：\n",
    "\n",
    "model （string，必填）\n",
    "\n",
    "要使用的模型ID。有关哪些模型适用于Chat API的详细信息\n",
    "\n",
    "messages （array，必填）\n",
    "\n",
    "迄今为止描述对话的消息列表\n",
    "\n",
    "role （string，必填）\n",
    "发送此消息的角色。system 、user 或 assistant 之一（一般用 user 发送用户问题，system 发送给模型提示信息）\n",
    "\n",
    "content （string，必填）\n",
    "\n",
    "消息的内容\n",
    "\n",
    "name （string，选填）\n",
    "\n",
    "此消息的发送者姓名。可以包含 a-z、A-Z、0-9 和下划线，最大长度为 64 个字符\n",
    "\n",
    "stream （boolean，选填，是否按流的方式发送内容）\n",
    "\n",
    "当它设置为 true 时，API 会以 SSE（ Server Side Event ）方式返回内容。SSE 本质上是一个长链接，会持续不断地输出内容直到完成响应。如果不是做实时聊天，默认false即可。\n",
    "\n",
    "max_tokens （integer，选填）\n",
    "\n",
    "在聊天补全中生成的最大 tokens 数。\n",
    "\n",
    "输入token和生成的token的总长度受模型上下文长度的限制。\n",
    "\n",
    "temperature （number，选填，默认是 1）\n",
    "\n",
    "采样温度，在 0和 2 之间。\n",
    "\n",
    "较高的值，如0.8会使输出更随机，而较低的值，如0.2会使其更加集中和确定性。\n",
    "\n",
    "通常建议修改这个（temperature ）或者 top_p ，但两者不能同时存在，二选一"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "message=[ \n",
    "         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "         {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=message,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "text = response.choices[0].message.content\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'Hello!'},\n",
       " ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.append(response.choices[0].message)\n",
    "\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "openai.types.chat.chat_completion_message.ChatCompletionMessage"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "new_message = response.choices[0].message\n",
    "type(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'Hello!'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': 'You are a helpful assistant.'},\n",
       " {'role': 'user', 'content': 'Hello!'},\n",
       " {'role': 'assistant', 'content': 'Hello! How can I assist you today?'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_message\n",
    "\n",
    "new_message_dict = {\"role\": new_message.role, \"content\": new_message.content}\n",
    "\n",
    "\n",
    "message.append(new_message_dict)\n",
    "\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chat = {\n",
    "    \"role\": \"user\",\n",
    "    \"content\": \"1.讲一个程序员才听得懂的冷笑话；2.今天是几号？3.明天星期几？\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "message.append(new_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'You are a helpful assistant.', 'role': 'system'},\n",
      " {'content': 'Hello!', 'role': 'user'},\n",
      " {'content': 'Hello! How can I assist you today?', 'role': 'assistant'},\n",
      " {'content': '1.讲一个程序员才听得懂的冷笑话；2.今天是几号？3.明天星期几？', 'role': 'user'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-96y80MvdkbpYYsMQ2NiVxKPlZVPOB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='1. 为什么程序员喜欢雨天？因为在雨天，他们可以计算云的高度。\\n2. 今天是几号？请告诉我您所在的时区，这样我才能告诉您今天的日期。\\n3. 明天星期几？请告诉我今天是星期几，这样我才能告诉您明天是星期几。', role='assistant', function_call=None, tool_calls=None))], created=1711448128, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint='fp_3bc1b5746c', usage=CompletionUsage(completion_tokens=113, prompt_tokens=74, total_tokens=187))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='1. 为什么程序员喜欢雨天？因为在雨天，他们可以计算云的高度。\\n2. 今天是几号？请告诉我您所在的时区，这样我才能告诉您今天的日期。\\n3. 明天星期几？请告诉我今天是星期几，这样我才能告诉您明天是星期几。', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "new_message = data.choices[0].message\n",
    "print(new_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
