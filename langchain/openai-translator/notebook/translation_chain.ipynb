{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI,ChatOpenAI\n",
    "from langchain_community.chat_models import QianfanChatEndpoint\n",
    "from langchain_core.language_models.chat_models import HumanMessage\n",
    "import os\n",
    "from langchain_community.chat_models.tongyi import ChatTongyi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(temperature=0,model_name=\"gpt-3.5-turbo\")\n",
    "qian_fan_model = QianfanChatEndpoint(streaming=True,temperature=0.1)\n",
    "chat_tongyi = ChatTongyi(streaming=True,temperature=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema  import SystemMessage, HumanMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages =[\n",
    "    SystemMessage(content='You are a helpful assistant.'),\n",
    "    HumanMessage(content=\"Who won the world series in 2020?\"),\n",
    "    AIMessage(content=\"The Los Angeles Dodgers won the World Series in 2020.\"), \n",
    "   HumanMessage(content=\"Where was it played?\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a helpful assistant.'),\n",
       " HumanMessage(content='Who won the world series in 2020?'),\n",
       " AIMessage(content='The Los Angeles Dodgers won the World Series in 2020.'),\n",
       " HumanMessage(content='Where was it played?')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_model.invoke(\"\"\"Take the letters in \\\n",
    "l-o-l-l-i-p-o-p and reverse them\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] [04-16 18:18:13] base.py:406 [t:6916]: retry is not available when stream is enabled\n",
      "[WARNING] [04-16 18:18:13] base.py:621 [t:6916]: This key `stop` does not seem to be a parameter that the model `ERNIE-Bot-turbo` will accept\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='lollipopopolliloollllo\\n\\nThe letters in l-o-l-l-i-p-o-p are rearranged and reversed to produce the resulting word or phrase \"lollipop\".', response_metadata={'token_usage': {}, 'model_name': 'ERNIE-Bot-turbo', 'finish_reason': 'stop'}, id='run-961f7455-798b-49a1-82b2-9bc76c482fdd-0')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qian_fan_model.invoke(\"\"\"Take the letters in \\\n",
    "l-o-l-l-i-p-o-p and reverse them\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Due to the COVID-19 pandemic, the 2020 World Series was held at a unique location without a home field advantage for either team. The games were played at two neutral sites: Dodger Stadium in Los Angeles, California, for the first two games and the American Airlines Center in Dallas, Texas, for the remaining games. The series took place from October 24 to October 28, 2020.', response_metadata={'model_name': 'qwen-turbo', 'finish_reason': 'stop', 'request_id': '4e373ce7-38ba-9d5d-9192-df4410d262f2', 'token_usage': {'input_tokens': 61, 'output_tokens': 91, 'total_tokens': 152}}, id='run-eae7643a-5906-46fe-9239-f2394df4a90e-0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_tongyi.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='p-o-p-i-l-l-o-l' response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 22, 'total_tokens': 30}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None} id='run-4cb3a564-3a30-4ae7-92f8-7e54859e5614-0'\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (PromptTemplate,HumanMessagePromptTemplate,ChatPromptTemplate,SystemMessagePromptTemplate,AIMessagePromptTemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 翻译任务指令始终由 System 角色承担\n",
    "template = (\n",
    "    \"\"\"You are a translation expert, proficient in various languages. \\n\n",
    "    Translates English to Chinese.\"\"\"\n",
    ")\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a translation expert, proficient in various languages. \\n\\n    Translates English to Chinese.'))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 待翻译文本由 Human 角色输入\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_message_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 System 和 Human 角色的提示模板构造 ChatPromptTemplate\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['text'] messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are a translation expert, proficient in various languages. \\n\\n    Translates English to Chinese.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['text'], template='{text}'))]\n"
     ]
    }
   ],
   "source": [
    "print(chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a translation expert, proficient in various languages. \\n\\n    Translates English to Chinese.'), HumanMessage(content='I love programming.')])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成用于翻译的 Chat Prompt\n",
    "chat_prompt_template.format_prompt(text=\"I love programming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = chat_prompt_template.format_prompt(text=\"I love programming.\").to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a translation expert, proficient in various languages. \\n\\n    Translates English to Chinese.'),\n",
       " HumanMessage(content='I love programming.')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = chat_prompt_template.format_messages(text='I love programming.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content='You are a translation expert, proficient in various languages. \\n\\n    Translates English to Chinese.'),\n",
       " HumanMessage(content='I love programming.')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='我喜欢编程。', response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 34, 'total_tokens': 42}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_c2295e73ad', 'finish_reason': 'stop', 'logprobs': None}, id='run-5e93bc03-def8-474c-8200-d5391bccee2e-0')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model.invoke(chat_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain,LLMChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " #无需再每次都使用 to_messages 方法构造 Chat Prompt\n",
    "translation_chain  = LLMChain(llm=chat_model,prompt=chat_prompt_template,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "qian_fan_translation_chain = LLMChain(llm=qian_fan_model,prompt=chat_prompt_template,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tongyi_translation_chain = LLMChain(llm=chat_tongyi,prompt= chat_prompt_template,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a translation expert, proficient in various languages. \n",
      "\n",
      "    Translates English to Chinese.\n",
      "Human: I love programming.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': '我喜欢编程。'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_chain.invoke({\n",
    "    \"text\": \"I love programming.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] [04-16 17:08:21] base.py:406 [t:6916]: retry is not available when stream is enabled\n",
      "[WARNING] [04-16 17:08:21] base.py:621 [t:6916]: This key `stop` does not seem to be a parameter that the model `ERNIE-Bot-turbo` will accept\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a translation expert, proficient in various languages. \n",
      "\n",
      "    Translates English to Chinese.\n",
      "Human: I love programming.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': '编程是一项非常有趣和有挑战性的工作，它需要大量的逻辑思维和解决问题的能力。很高兴听到你对编程感兴趣。你最喜欢编程的哪个方面呢？'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qian_fan_translation_chain.invoke({\n",
    "    \"text\": \"I love programming.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a translation expert, proficient in various languages. \n",
      "\n",
      "    Translates English to Chinese.\n",
      "Human: I love programming.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': '我热爱编程。'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tongyi_translation_chain.invoke({\n",
    "    \"text\": \"I love programming.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a translation expert, proficient in various languages. \n",
      "\n",
      "    Translates English to Chinese.\n",
      "Human: I love AI and Large Language Model.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': '我喜欢人工智能和大型语言模型。'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_chain.invoke({'text': \"I love AI and Large Language Model.\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] [04-16 17:08:24] base.py:406 [t:6916]: retry is not available when stream is enabled\n",
      "[WARNING] [04-16 17:08:24] base.py:621 [t:6916]: This key `stop` does not seem to be a parameter that the model `ERNIE-Bot-turbo` will accept\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a translation expert, proficient in various languages. \n",
      "\n",
      "    Translates English to Chinese.\n",
      "Human: I love AI and Large Language Model.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': 'I am glad to hear that you love AI and Large Language Model. AI and Large Language Model are becoming increasingly important in modern society, and they have made great progress in various fields. I hope you can continue to explore and learn more about AI and Large Language Model, and share your experiences with me.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qian_fan_translation_chain.invoke({'text': \"I love AI and Large Language Model.\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a translation expert, proficient in various languages. \n",
      "\n",
      "    Translates English to Chinese.\n",
      "Human: ['Fruit', 'Color', 'Price (USD)'] [Apple, Red, 1.20], [Banana, Yellow, 0.50] [Orange, Orange, 0.80] [Strawberry, Red, 2.50] [Blueberry, Blue, 3.00] [Kiwi, Green, 1.00] [Mango, Orange, 1.50] [Grape, Purple, 2.00]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': \"['水果', '颜色', '价格（美元）'] [苹果，红色，1.20] [香蕉，黄色，0.50] [橙子，橙色，0.80] [草莓，红色，2.50] [蓝莓，蓝色，3.00] [猕猴桃，绿色，1.00] [芒果，橙色，1.50] [葡萄，紫色，2.00]\"}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translation_chain.invoke({'text': \"['Fruit', 'Color', 'Price (USD)'] [Apple, Red, 1.20], [Banana, Yellow, 0.50] [Orange, Orange, 0.80] [Strawberry, Red, 2.50] [Blueberry, Blue, 3.00] [Kiwi, Green, 1.00] [Mango, Orange, 1.50] [Grape, Purple, 2.00]\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 翻译任务指令始终由 System 角色承担\n",
    "template = (\n",
    "    \"\"\"You are a translation expert, proficient in various languages. \\n\n",
    "    Translates {source_language} to {target_language}.\"\"\"\n",
    ")\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(template) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['source_language', 'target_language'], template='You are a translation expert, proficient in various languages. \\n\\n    Translates {source_language} to {target_language}.'))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_message_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 待翻译文本由 Human 角色输入\n",
    "human_template = \"{text}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用 System 和 Human 角色的提示模板构造 ChatPromptTemplate\n",
    "m_chat_prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_translation_chain = LLMChain(llm=chat_model, verbose=True,prompt=m_chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a translation expert, proficient in various languages. \n",
      "\n",
      "    Translates Chinese to English.\n",
      "Human: 我喜欢学习大语言模型，轻松简单又愉快\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'source_language': 'Chinese',\n",
       " 'target_language': 'English',\n",
       " 'text': 'I enjoy studying large language models, which are easy, simple, and enjoyable.'}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_translation_chain.invoke({\n",
    "    \"source_language\": \"Chinese\",\n",
    "    \"target_language\": \"English\",\n",
    "    \"text\": \"我喜欢学习大语言模型，轻松简单又愉快\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "from langchain_core.memory import BaseMemory\n",
    "from langchain_core.prompts import BasePromptTemplate\n",
    "from langchain_core.pydantic_v1 import Extra, Field, root_validator\n",
    "\n",
    "from langchain.chains.conversation.prompt import PROMPT\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.memory.buffer import ConversationBufferMemory\n",
    "from langchain_core.runnables import (\n",
    "    RunnableConfig,\n",
    "    RunnableSerializable,\n",
    "    ensure_config,\n",
    "    run_in_executor,\n",
    ")\n",
    "from typing import Any, Dict, List, Optional, Type, Union, cast\n",
    "\n",
    "class TranslationChain(LLMChain):\n",
    "    prompt: BasePromptTemplate \n",
    "    \n",
    "    output_key: str = \"response\"  #: :meta private:\n",
    "\n",
    "    class Config:\n",
    "        extra = Extra.forbid\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "    @property\n",
    "    def input_keys(self) -> List[str]:\n",
    "        \"\"\"Will be whatever keys the prompt expects.\n",
    "\n",
    "        :meta private:\n",
    "        \"\"\"\n",
    "        return self.prompt.input_variables\n",
    "\n",
    "    @property\n",
    "    def output_keys(self) -> List[str]:\n",
    "        \"\"\"Will always return text key.\n",
    "\n",
    "        :meta private:\n",
    "        \"\"\"\n",
    "        return [self.output_key]\n",
    "    \n",
    "    def invoke(\n",
    "        self,\n",
    "        input: Dict[str, Any],\n",
    "        config: Optional[RunnableConfig] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> Dict[str, Any]:\n",
    "        if 'source_language' not in input or input['source_language'] is None:\n",
    "            input['source_language'] = 'Chinese'\n",
    "        if 'target_language' not in input or input['target_language'] is None:\n",
    "            input['target_language'] = 'English'\n",
    "        return super().invoke(input, config, **kwargs)        \n",
    "\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_translation_chain = TranslationChain(llm=chat_model, verbose=True,prompt=m_chat_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new TranslationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: You are a translation expert, proficient in various languages. \n",
      "\n",
      "    Translates English to Chinese.\n",
      "Human: I enjoy studying large language models, it's easy, simple, and enjoyable.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'text': \"I enjoy studying large language models, it's easy, simple, and enjoyable.\",\n",
       " 'source_language': 'English',\n",
       " 'target_language': 'Chinese',\n",
       " 'response': '我喜欢研究大型语言模型，这很容易、简单且令人愉悦。'}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_translation_chain.invoke(input={\n",
    "    \"text\": \"I enjoy studying large language models, it's easy, simple, and enjoyable.\",\n",
    "    \"source_language\":'English',\n",
    "    \"target_language\":'Chinese',\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
